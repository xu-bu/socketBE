<!DOCTYPE html>
<html>
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<style>
  body { 
    font-family: Arial, sans-serif; 
    padding: 20px;
    max-width: 600px;
    margin: 0 auto;
  }
  .button { 
    padding: 15px 30px; 
    font-size: 18px; 
    background: #4CAF50; 
    color: white; 
    border: none; 
    border-radius: 5px; 
    cursor: pointer;
    margin: 5px;
  }
  .button:active { background: #45a049; }
  .button:disabled { background: #ccc; cursor: not-allowed; }
  .button.error { background: #f44336; }
  .card {
    background: #f0f0f0;
    padding: 15px;
    margin-bottom: 20px;
    border-radius: 8px;
  }
  .status {
    padding: 10px;
    margin-bottom: 10px;
    background: #fff3cd;
    border-radius: 5px;
  }
  .info {
    font-size: 14px;
    color: #666;
    margin-top: 10px;
  }
</style>
</head>
<body>
<h2>üéß PCM Audio Receiver</h2>

<div class="card">
  <strong>Room: r1</strong><br>
  <span id="userList">Connecting...</span>
</div>

<div id="status" class="status">
  Status: Waiting for audio stream...
</div>

<button id="enableAudio" class="button" style="display: none;">
  üîä Click to Enable Audio
</button>

<button id="quitBtn" class="button error">
  ‚ùå Quit Room
</button>

<div class="info">
  <strong>Instructions:</strong><br>
  ‚Ä¢ This receiver handles raw PCM audio from Android app<br>
  ‚Ä¢ Audio format: 44100 Hz, 16-bit, Stereo<br>
  ‚Ä¢ Click "Enable Audio" if autoplay is blocked
</div>

<script>
const ws = new WebSocket("wss://socketbe.onrender.com");
let audioContext;
let audioQueue = [];
let isPlaying = false;
let nextPlayTime = 0;

ws.onopen = () => {
  ws.send(JSON.stringify({ type: "join", roomId: "r1", userId: "PCMReceiver" }));
  updateStatus("Connected - Waiting for audio...");
};

function updateStatus(msg) {
  document.getElementById("status").textContent = "Status: " + msg;
  console.log("Status:", msg);
}

function updateRoomStatus(users) {
  const userList = document.getElementById("userList");
  if (users.length === 0) {
    userList.textContent = "No users in room";
  } else {
    userList.textContent = `Users in room (${users.length}): ${users.join(", ")}`;
  }
}

function initAudioContext() {
  if (audioContext) return;
  
  audioContext = new (window.AudioContext || window.webkitAudioContext)({
    sampleRate: 44100
  });
  
  console.log("AudioContext initialized, sample rate:", audioContext.sampleRate);
  updateStatus("Audio context ready - Listening for PCM data...");
}

function playPCMData(pcmData) {
  if (!audioContext) {
    console.log("AudioContext not initialized, trying now...");
    initAudioContext();
  }
  
  if (audioContext.state === 'suspended') {
    audioContext.resume();
  }
  
  // Convert PCM bytes to Float32Array for Web Audio API
  const int16Array = new Int16Array(pcmData);
  const float32Array = new Float32Array(int16Array.length);
  
  // Convert 16-bit PCM to float32 (-1.0 to 1.0)
  for (let i = 0; i < int16Array.length; i++) {
    float32Array[i] = int16Array[i] / 32768.0;
  }
  
  // Create audio buffer (stereo)
  const samples = float32Array.length / 2;
  const audioBuffer = audioContext.createBuffer(2, samples, 44100);
  
  // De-interleave stereo data
  const leftChannel = audioBuffer.getChannelData(0);
  const rightChannel = audioBuffer.getChannelData(1);
  
  for (let i = 0; i < samples; i++) {
    leftChannel[i] = float32Array[i * 2];
    rightChannel[i] = float32Array[i * 2 + 1];
  }
  
  // Create and schedule buffer source
  const source = audioContext.createBufferSource();
  source.buffer = audioBuffer;
  source.connect(audioContext.destination);
  
  // Schedule playback
  const currentTime = audioContext.currentTime;
  if (nextPlayTime < currentTime) {
    nextPlayTime = currentTime;
  }
  
  source.start(nextPlayTime);
  nextPlayTime += audioBuffer.duration;
  
  if (!isPlaying) {
    isPlaying = true;
    updateStatus("üîä Playing PCM audio!");
  }
}

// Enable audio button
document.getElementById("enableAudio").onclick = () => {
  initAudioContext();
  if (audioContext && audioContext.state === 'suspended') {
    audioContext.resume().then(() => {
      updateStatus("Audio enabled and ready!");
      document.getElementById("enableAudio").style.display = "none";
    });
  }
};

// Quit button
document.getElementById("quitBtn").onclick = () => {
  if (confirm("Are you sure you want to quit the room?")) {
    if (audioContext) {
      audioContext.close();
      audioContext = null;
    }
    ws.close();
    updateStatus("Disconnected");
    document.getElementById("quitBtn").disabled = true;
    document.getElementById("userList").textContent = "Not connected";
  }
};

ws.onmessage = async (e) => {
  // Handle binary PCM data
  if (e.data instanceof Blob) {
    const arrayBuffer = await e.data.arrayBuffer();
    playPCMData(arrayBuffer);
    return;
  }
  
  // Handle text messages (JSON)
  const msg = JSON.parse(e.data);
  
  if (msg.type === "roomUpdate") {
    updateRoomStatus(msg.users);
  }
};

ws.onerror = (error) => {
  console.error("WebSocket error:", error);
  updateStatus("Connection error!");
};

ws.onclose = () => {
  updateStatus("Disconnected from server");
  isPlaying = false;
};

// Try to initialize audio context on user interaction
document.addEventListener('click', () => {
  if (!audioContext) {
    try {
      initAudioContext();
    } catch (e) {
      console.log("Need explicit button click:", e);
      document.getElementById("enableAudio").style.display = "block";
    }
  }
}, { once: true });
</script>
</body>
</html>